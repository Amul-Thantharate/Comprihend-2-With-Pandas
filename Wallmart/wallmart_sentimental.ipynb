{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "                                       AWS Comprehend Sentiment Analysis Using Python\n",
    "This notebook shows how to use boto3 Amazon API to use Amazon Comprehend for real time analysis as well as scheduling analysis jobs.\n",
    "\n",
    "1. For boto3 to work you need to create an IAM User, receive aws_access_key_id and aws_secret_access_key and configure your credentials using AWS Command Line Interface (AWS CLI)\n",
    "2. Cost. If you are using free AWS tier, you can analyze 50K units a month free. Every unit is 100 characters. In my example, every tweet is ~2 units. In the scheduled job I am analyzing 10K tweets at once, so the free tier runs out pretty fast, and then it's $1 per 10K. Be sure to check pricing before you proceed. https://aws.amazon.com/comprehend/pricing/\n",
    "3. Reference. Boto3 S3: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/comprehend.html Boto3 Comprehend: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wallmart_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tony Hawkâ€™s Pro Skater 1+2 (PS4) is $33.88 on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@CassieFambro we were just saying that yesterd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@lxoG21 I love me some Walmart candles lol the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I actually am too ðŸ¤” need to go shopping. 24/7 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@diancalondon Bill was.....Sunday morning Khak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     wallmart_tweets\n",
       "0  Tony Hawkâ€™s Pro Skater 1+2 (PS4) is $33.88 on ...\n",
       "1  @CassieFambro we were just saying that yesterd...\n",
       "2  @lxoG21 I love me some Walmart candles lol the...\n",
       "3  I actually am too ðŸ¤” need to go shopping. 24/7 ...\n",
       "4  @diancalondon Bill was.....Sunday morning Khak..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd\n",
    "import json\n",
    "import tarfile\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "link_data = \"https://github.com/Amul-Thantharate/Comprihend-2-With-Pandas/blob/main/wallmarts_tweets.csv?raw=true\"\n",
    "local_file_name = \"Comprehend/wallmarts_tweets_1k.csv\"\n",
    "df = pd.read_csv(link_data, header=None, names=['wallmart_tweets'], dtype=str, encoding='utf-8')\n",
    "df.to_csv(local_file_name, index=False, header=False, encoding='utf-8')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                            Real Time Single Record Processing \n",
    "                                        Using this type of processing you can analyze one piece of text of up to 5K bytes long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@diancalondon Bill was.....Sunday morning Khaki Walmart fly....in his own way...the heart wants what it wants. Yeah. Maybe the pickens are slim midwest? The only one I understood and felt bad for was Barb, because she felt she owed Bill for being there. https://t.co/BOCvIDvAmc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NEUTRAL'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "text = df.loc[4].item()\n",
    "# print(text)\n",
    "comprehend = boto3.client(service_name='comprehend', region_name='us-east-1')\n",
    "sentiment_output = comprehend.detect_sentiment(Text=text, LanguageCode='en')\n",
    "# sentiment_output\n",
    "sentiment_output['SentimentScore']\n",
    "sentiment_output['Sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                                    Real-Time Batch Processing \n",
    "*** Up to 25 documents of up to 5,000 bytes each, submitted in a list. For larger jobs, use the Async Batch API. ***\n",
    "\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Index': 10,\n",
       " 'Sentiment': 'NEUTRAL',\n",
       " 'SentimentScore': {'Positive': 0.31565114855766296,\n",
       "  'Negative': 0.15727275609970093,\n",
       "  'Neutral': 0.5268921256065369,\n",
       "  'Mixed': 0.0001840569166233763}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = list(df.wallmart_tweets[0:25])\n",
    "# print(text_list)\n",
    "sentiment_batch = comprehend.batch_detect_sentiment(TextList=text_list, LanguageCode='en')\n",
    "text_list[10]\n",
    "sentiment_batch['ResultList'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@diancalondon Bill was.....Sunday morning Khaki Walmart fly....in his own way...the heart wants what it wants. Yeah. Maybe the pickens are slim midwest? The only one I understood and felt bad for was Barb, because she felt she owed Bill for being there. https://t.co/BOCvIDvAmc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Mixed</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.999075</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.033051</td>\n",
       "      <td>0.472191</td>\n",
       "      <td>0.494564</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994689</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.079764</td>\n",
       "      <td>0.101556</td>\n",
       "      <td>0.812737</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.074933</td>\n",
       "      <td>0.331529</td>\n",
       "      <td>0.593397</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Positive  Negative   Neutral     Mixed Sentiment\n",
       "Index                                                  \n",
       "0      0.000829  0.000085  0.999075  0.000011   NEUTRAL\n",
       "1      0.033051  0.472191  0.494564  0.000194   NEUTRAL\n",
       "2      0.994689  0.000110  0.005175  0.000027  POSITIVE\n",
       "3      0.079764  0.101556  0.812737  0.005943   NEUTRAL\n",
       "4      0.074933  0.331529  0.593397  0.000140   NEUTRAL"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def parse_sentiment_batch(data):\n",
    "    df = pd.DataFrame([item['SentimentScore'] for item in data['ResultList']])\n",
    "    df['Sentiment'] = [item.get('Sentiment') for item in data['ResultList']]\n",
    "    df['Index'] = [item.get('Index') for item in data['ResultList']]\n",
    "    df.set_index('Index', inplace=True)\n",
    "    \n",
    "    return df\n",
    "print(text)\n",
    "parse_sentiment_batch(sentiment_batch).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
